"""
DoH è¡¨æ ¼è§£ææ¨¡å—
è´Ÿè´£ä» Markdown è¡¨æ ¼ä¸­æå– DoH æœåŠ¡å™¨ä¿¡æ¯
"""

import re
from typing import Dict, List
from urllib.parse import urlparse


class DoHTableParser:
    """DoH æœåŠ¡å™¨è¡¨æ ¼è§£æå™¨"""
    
    def __init__(self, content: str):
        self.content = content
        self.provider_urls = {}
    
    def parse(self) -> Dict[str, List[str]]:
        """
        è§£æ DoH æœåŠ¡å™¨è¡¨æ ¼
        
        è¡¨æ ¼æ ¼å¼:
        | Who runs it | Base URL | Working*| Comment** |
        
        Returns:
            Dict[str, List[str]]: {æä¾›å•†åç§°: [DoH URLs]}
        """
        print("\nğŸ“‹ å¼€å§‹è§£æ DoH è¡¨æ ¼...")
        
        lines = self.content.split('\n')
        current_provider = None
        in_table = False
        
        for line in lines:
            # æ£€æµ‹è¡¨æ ¼å¼€å§‹
            if '| Who runs it | Base URL |' in line:
                in_table = True
                continue
            
            # æ£€æµ‹è¡¨æ ¼ç»“æŸ
            if in_table and (not line.strip() or line.startswith('#')):
                in_table = False
                continue
            
            # è·³è¿‡è¡¨å¤´åˆ†éš”çº¿
            if in_table and '|---' in line:
                continue
            
            # è§£æè¡¨æ ¼è¡Œ
            if in_table and line.strip().startswith('|'):
                self._parse_table_row(line, current_provider)
                
                # æ›´æ–°å½“å‰æä¾›å•†
                provider = self._extract_provider_name(line)
                if provider:
                    current_provider = provider
        
        total_providers = len(self.provider_urls)
        total_urls = sum(len(urls) for urls in self.provider_urls.values())
        
        print(f"âœ“ è§£æå®Œæˆ: {total_providers} ä¸ªæä¾›å•†, {total_urls} ä¸ª DoH URL")
        
        return self.provider_urls
    
    def _parse_table_row(self, line: str, current_provider: str):
        """è§£æå•è¡Œè¡¨æ ¼"""
        columns = [col.strip() for col in line.split('|')]
        
        if len(columns) < 4:
            return
        
        base_url_col = columns[2]  # Base URL åˆ—
        
        # æå– DoH URLs
        if base_url_col.strip() and current_provider:
            urls = self._extract_doh_urls(base_url_col)
            
            if urls:
                if current_provider not in self.provider_urls:
                    self.provider_urls[current_provider] = []
                
                self.provider_urls[current_provider].extend(urls)
    
    def _extract_provider_name(self, line: str) -> str:
        """ä»è¡¨æ ¼è¡Œä¸­æå–æä¾›å•†åç§°"""
        columns = [col.strip() for col in line.split('|')]
        
        if len(columns) < 2:
            return None
        
        who_runs_it = columns[1]
        
        # è·³è¿‡åˆ†ç±»è¡Œï¼ˆå¦‚ **A**, **B**ï¼‰
        if who_runs_it.strip().startswith('**') and len(who_runs_it.strip()) <= 5:
            return None
        
        if not who_runs_it.strip():
            return None
        
        # æå–æä¾›å•†åç§°ï¼ˆå»é™¤ Markdown é“¾æ¥ï¼‰
        provider_match = re.search(r'\[([^\]]+)\]', who_runs_it)
        if provider_match:
            return provider_match.group(1).strip()
        else:
            return who_runs_it.strip()
    
    def _extract_doh_urls(self, text: str) -> List[str]:
        """ä»æ–‡æœ¬ä¸­æå– DoH URLs"""
        # æŸ¥æ‰¾æ‰€æœ‰ https:// å¼€å¤´çš„ URL
        urls = re.findall(r'https://[^\s<>|)]+', text)
        
        valid_urls = []
        for url in urls:
            # æ¸…ç† URL
            url = url.rstrip(')')
            
            # ç¡®ä¿æ˜¯ DoH URLï¼ˆåŒ…å«å¸¸è§çš„ DoH è·¯å¾„ï¼‰
            if self._is_doh_url(url):
                valid_urls.append(url)
        
        return valid_urls
    
    def _is_doh_url(self, url: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºæœ‰æ•ˆçš„ DoH URL"""
        doh_patterns = [
            '/dns-query',
            '/dns',
            '/doh',
            '/query',
            'dns.',
            'doh.',
        ]
        
        return any(pattern in url.lower() for pattern in doh_patterns)
    
    @staticmethod
    def extract_domain(url: str) -> str:
        """ä» URL æå–åŸŸå"""
        try:
            parsed = urlparse(url)
            return parsed.netloc
        except:
            return None