"""
è§„åˆ™æ–‡ä»¶ç”Ÿæˆæ¨¡å—
ç”Ÿæˆ Mihomo æ ¼å¼çš„ YAML è§„åˆ™æ–‡ä»¶
"""

import os
import yaml
from typing import Dict, List, Set
from datetime import datetime
from .config import OUTPUT_DIR, OUTPUT_FILES, YAML_CONFIG
from .parser import DoHTableParser


class RulesetGenerator:
    """è§„åˆ™æ–‡ä»¶ç”Ÿæˆå™¨"""
    
    def __init__(self, output_dir: str = OUTPUT_DIR):
        self.output_dir = output_dir
        self._ensure_output_dir()
    
    def _ensure_output_dir(self):
        """ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨"""
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)
            print(f"âœ“ åˆ›å»ºè¾“å‡ºç›®å½•: {self.output_dir}")
    
    def generate_all(self, 
                     china_providers: Dict[str, List[str]], 
                     foreign_providers: Dict[str, List[str]],
                     reasons: Dict[str, str]):
        """
        ç”Ÿæˆæ‰€æœ‰è§„åˆ™æ–‡ä»¶
        
        Args:
            china_providers: ä¸­å›½ DoH æä¾›å•†
            foreign_providers: å¢ƒå¤– DoH æä¾›å•†
            reasons: åˆ†ç±»ä¾æ®
        """
        print(f"\nğŸ“ å¼€å§‹ç”Ÿæˆè§„åˆ™æ–‡ä»¶...")
        
        # ç”Ÿæˆ YAML æ ¼å¼ï¼ˆMihomo ä½¿ç”¨ï¼‰
        foreign_count = self._generate_yaml(
            foreign_providers,
            OUTPUT_FILES['foreign_yaml'],
            "å¢ƒå¤– DoH (å»ºè®®ä»£ç†)"
        )
        
        china_count = self._generate_yaml(
            china_providers,
            OUTPUT_FILES['china_yaml'],
            "å›½å†… DoH (å»ºè®®ç›´è¿)"
        )
        
        # ç”Ÿæˆ List æ ¼å¼ï¼ˆå¤‡ç”¨ï¼‰
        self._generate_list(
            foreign_providers,
            OUTPUT_FILES['foreign_list'],
            "å¢ƒå¤– DoH (å»ºè®®ä»£ç†)"
        )
        
        self._generate_list(
            china_providers,
            OUTPUT_FILES['china_list'],
            "å›½å†… DoH (å»ºè®®ç›´è¿)"
        )
        
        # ç”Ÿæˆåˆ†ç±»æ—¥å¿—
        self._generate_classification_log(
            china_providers,
            foreign_providers,
            reasons
        )
        
        print(f"\nâœ… è§„åˆ™æ–‡ä»¶ç”Ÿæˆå®Œæˆ!")
        print(f"   å¢ƒå¤– DoH: {foreign_count} ä¸ªåŸŸå")
        print(f"   å›½å†… DoH: {china_count} ä¸ªåŸŸå")
    
    def _generate_yaml(self, 
                       providers: Dict[str, List[str]], 
                       filename: str,
                       title: str) -> int:
        """
        ç”Ÿæˆ YAML æ ¼å¼è§„åˆ™æ–‡ä»¶ï¼ˆMihomo rule-provider æ ¼å¼ï¼‰
        ï¼Œå¹¶æŒ‰æä¾›å•†åˆ†ç»„æ·»åŠ æ³¨é‡Šã€‚
        
        Returns:
            int: åŸŸåæ•°é‡
        """
        provider_domains, all_domains = self._group_domains_by_provider(providers)
        
        if not all_domains:
            print(f"âš ï¸  è·³è¿‡ {filename}: æ— æ•°æ®")
            return 0
        
        filepath = os.path.join(self.output_dir, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            # å†™å…¥æ³¨é‡Š
            f.write(f"# DoH Servers Ruleset - {title}\n")
            f.write(f"# Auto-generated from curl/curl wiki\n")
            f.write(f"# Generated at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"# Total domains: {len(all_domains)}\n")
            f.write(f"# Format: Mihomo rule-provider (behavior: domain)\n\n")
            
            # å†™å…¥åˆ†ç»„åçš„ payload
            f.write("payload:\n")
            for provider in sorted(provider_domains.keys()):
                domains = sorted(provider_domains[provider])
                if not domains:
                    continue
                f.write(f"  # {provider}\n")
                for domain in domains:
                    f.write(f"  - {domain}\n")
        
        print(f"âœ“ {filename}: {len(all_domains)} ä¸ªåŸŸå")
        return len(all_domains)
    
    def _generate_list(self,
                       providers: Dict[str, List[str]],
                       filename: str,
                       title: str):
        """ç”Ÿæˆ List æ ¼å¼è§„åˆ™æ–‡ä»¶ï¼ˆDOMAIN-SUFFIXï¼‰ï¼ŒæŒ‰æä¾›å•†åˆ†ç»„å¹¶æ·»åŠ æ³¨é‡Š"""
        provider_domains, all_domains = self._group_domains_by_provider(providers)
        
        if not all_domains:
            return
        
        filepath = os.path.join(self.output_dir, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(f"# DoH Servers Ruleset - {title}\n")
            f.write(f"# Auto-generated from curl/curl wiki\n")
            f.write(f"# Generated at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"# Total rules: {len(all_domains)}\n\n")
            
            for provider in sorted(provider_domains.keys()):
                domains = sorted(provider_domains[provider])
                if not domains:
                    continue
                f.write(f"# {provider}\n")
                for domain in domains:
                    f.write(f"DOMAIN-SUFFIX,{domain}\n")
                f.write("\n")
        
        print(f"âœ“ {filename}: {len(all_domains)} æ¡è§„åˆ™")
    
    def _generate_classification_log(self,
                                     china_providers: Dict[str, List[str]],
                                     foreign_providers: Dict[str, List[str]],
                                     reasons: Dict[str, str]):
        """ç”Ÿæˆåˆ†ç±»æ—¥å¿—"""
        filepath = os.path.join(self.output_dir, OUTPUT_FILES['classification_log'])
        
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write("DoH æä¾›å•†åˆ†ç±»æ—¥å¿—\n")
            f.write("=" * 70 + "\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"åˆ†ç±»æ–¹æ³•: GeoIP\n\n")
            
            # ä¸­å›½æä¾›å•†
            f.write(f"ğŸ‡¨ğŸ‡³ ä¸­å›½ DoH æä¾›å•† ({len(china_providers)} ä¸ª)\n")
            f.write("-" * 70 + "\n\n")
            
            for provider in sorted(china_providers.keys()):
                f.write(f"[{provider}]\n")
                f.write(f"åˆ†ç±»ä¾æ®: {reasons.get(provider, 'æœªçŸ¥')}\n")
                f.write(f"URL æ•°é‡: {len(china_providers[provider])}\n")
                f.write("URLs:\n")
                for url in china_providers[provider]:
                    f.write(f"  - {url}\n")
                f.write("\n")
            
            # å¢ƒå¤–æä¾›å•†ï¼ˆåªæ˜¾ç¤ºå‰20ä¸ªï¼‰
            f.write(f"\nğŸŒ å¢ƒå¤– DoH æä¾›å•† ({len(foreign_providers)} ä¸ª)\n")
            f.write("-" * 70 + "\n\n")
            
            for provider in sorted(foreign_providers.keys())[:20]:
                f.write(f"[{provider}]\n")
                f.write(f"åˆ†ç±»ä¾æ®: {reasons.get(provider, 'æœªçŸ¥')}\n")
                f.write(f"URL æ•°é‡: {len(foreign_providers[provider])}\n")
                for url in foreign_providers[provider][:2]:
                    f.write(f"  - {url}\n")
                f.write("\n")
            
            if len(foreign_providers) > 20:
                f.write(f"... è¿˜æœ‰ {len(foreign_providers) - 20} ä¸ªå¢ƒå¤–æä¾›å•†\n")
        
        print(f"âœ“ {OUTPUT_FILES['classification_log']}: åˆ†ç±»æ—¥å¿—")
    
    def _group_domains_by_provider(self, providers: Dict[str, List[str]]):
        """æŒ‰æä¾›å•†åˆ†ç»„åŸŸåï¼ŒåŒæ—¶ä¿è¯å…¨å±€åŸŸåä¸é‡å¤"""
        provider_domains: Dict[str, List[str]] = {}
        all_domains: Set[str] = set()
        
        for provider, urls in providers.items():
            for url in urls:
                domain = DoHTableParser.extract_domain(url)
                if not domain or domain in all_domains:
                    continue
                all_domains.add(domain)
                if provider not in provider_domains:
                    provider_domains[provider] = []
                provider_domains[provider].append(domain)
        
        return provider_domains, all_domains